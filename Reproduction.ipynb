{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import f1_score, jaccard_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from skmultilearn.ensemble import RakelD\n",
    "from bow import BOW"
   ]
  },
  {
   "source": [
    "# Data\n",
    "\n",
    "source: https://github.com/NLeSC/spudisc-emotion-classification\n",
    "\n",
    "Preprocessed versions of the data, split for training and testing a classifier, can be found in the files train.txt and test.txt. These contain one sentence per line with labels at the end of each line. A single space separates the labels from the text. Multiple labels are separated by underscores. Where a sentence received no label, the string None appears. (No label means no emotions assigned by the annotator; all sentences have been annotated.)\n",
    "\n",
    "ToDo: \n",
    "- cite and description of data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILES = Path('./data/')\n",
    "TEST_DATA = DATA_FILES / 'test.txt'\n",
    "TRAIN_DATA = DATA_FILES / 'train.txt'\n",
    "\n",
    "train_sentences, train_labels = BOW().load_data_raw(TRAIN_DATA)\n",
    "test_sentences, test_labels = BOW().load_data_raw(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(503,)\n(503,)\n(126,)\n(126,)\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_sentences.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "source": [
    "# Features\n",
    "\n",
    "Both algorithms use standard bag-of-words features with stop word removal and optional tfâ€“idf weighting.\n",
    "\n",
    "## BOW and Tf-idf\n",
    "\n",
    "described at: https://medium.com/betacom/bow-tf-idf-in-python-for-unsupervised-learning-task-88f3b63ccd6d\n",
    "\n",
    "scikit BOW: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "\n",
    "scit tfid: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer\n",
    "\n",
    "### Stop word removal\n",
    "\n",
    "described at: https://aisb.org.uk/wp-content/uploads/2019/12/Final-vol-02.pdf#page=59\n",
    "\n",
    "ToDo\n",
    "- describe how the features are created"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = BOW(\n",
    "    stop_words=True,\n",
    "    tfidf=True,\n",
    "    log=True,\n",
    ")\n",
    "X_train, X_test, y_train, y_test = bow.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(503, 2168)\n(503, 8)\n(126, 2168)\n(126, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Algorithms\n",
    "\n",
    "## One-vs-Rest\n",
    "\n",
    "Reduction to Binary classifyers\n",
    "\n",
    "implementation of liblinear in sklearn is used which can be found in: https://scikit-learn.org/stable/modules/generated/\n",
    "sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC\n",
    "\n",
    "wrapper: https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier\n",
    "\n",
    "description at: https://scikit-learn.org/stable/modules/svm.html (chapter 1.4.1.1.)\n",
    "\n",
    "ToDo\n",
    "- oversampling\n",
    "- todo find best parameters per emotion and seperatly optimise models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr = OneVsRestClassifier(\n",
    "    LinearSVC(penalty='l1', dual=False, max_iter=10e3))"
   ]
  },
  {
   "source": [
    "## RAKEL\n",
    "\n",
    "implementation found in: http://scikit.ml/api/skmultilearn.ensemble.rakeld.html\n",
    "\n",
    "ToDo:\n",
    "- automatic oversampling\n",
    "\n",
    "Difficultys:\n",
    "- not clear if L1 or L2 penalty (use L2 as it is default)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rakel = RakelD(\n",
    "    base_classifier=LinearSVC(C=1),\n",
    "    base_classifier_require_dense=[True, True],\n",
    "    labelset_size=3\n",
    ")"
   ]
  },
  {
   "source": [
    "# Benchmark\n",
    "\n",
    "ToDo\n",
    "- set seed\n",
    "\n",
    "Difficulties\n",
    "- how many runs were performed to calculate variance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(bow, ovr, rakel, num_runs=50):\n",
    "    results_all_runs = []\n",
    "\n",
    "    X_train, X_test, y_train, y_test = bow.create()\n",
    "    labels = bow.get_labels()\n",
    "\n",
    "    for n in range(num_runs):\n",
    "        # run OvR model\n",
    "        ovr.fit(X_train, y_train)\n",
    "        ovr_prediction = ovr.predict(X_test)\n",
    "        ovr_f1 = f1_score(y_test, ovr_prediction, average=None)\n",
    "        ovr_accuracy = jaccard_score(y_test, ovr_prediction, average=None)\n",
    "\n",
    "        # run RAKEL model\n",
    "        rakel.fit(X_train, y_train)\n",
    "        rakel_prediction = rakel.predict(X_test)\n",
    "        rakel_f1 = f1_score(y_test, rakel_prediction, average=None)\n",
    "        rakel_accuracy = jaccard_score(y_test, rakel_prediction, average=None)\n",
    "\n",
    "        # capture results in DataFrame\n",
    "        results = pd.DataFrame({\n",
    "            'Emotion': labels,\n",
    "            'run': n,\n",
    "            'ovr_f1': ovr_f1,\n",
    "            'ovr_accuracy': ovr_accuracy,\n",
    "            'rakel_f1': rakel_f1,\n",
    "            'rakel_accuracy': rakel_accuracy,\n",
    "        })\n",
    "        results_all_runs.append(results)\n",
    "\n",
    "    return pd.concat(results_all_runs), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, labels = benchmark(bow, ovr, rakel, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(160, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Emotion  run    ovr_f1  ovr_accuracy  rakel_f1  rakel_accuracy\n",
       "0     Anger    0  0.000000      0.000000  0.000000        0.000000\n",
       "1      Fear    0  0.285714      0.166667  0.000000        0.000000\n",
       "2  Interest    0  0.071429      0.037037  0.000000        0.000000\n",
       "3       Joy    0  0.500000      0.333333  0.266667        0.153846\n",
       "4      Love    0  0.500000      0.333333  0.580000        0.408451"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Emotion</th>\n      <th>run</th>\n      <th>ovr_f1</th>\n      <th>ovr_accuracy</th>\n      <th>rakel_f1</th>\n      <th>rakel_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Anger</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Fear</td>\n      <td>0</td>\n      <td>0.285714</td>\n      <td>0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Interest</td>\n      <td>0</td>\n      <td>0.071429</td>\n      <td>0.037037</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Joy</td>\n      <td>0</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.266667</td>\n      <td>0.153846</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Love</td>\n      <td>0</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>0.580000</td>\n      <td>0.408451</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['Anger', 'Fear', 'Interest', 'Joy', 'Love', 'None', 'Sadness',\n",
       "       'Surprise'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "source": [
    "# Results\n",
    "\n",
    "ToDo\n",
    "- compute overall results per emotion for all runs\n",
    "- compute variances"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calulate_results(scores, labels):\n",
    "    grouped = scores.groupby('Emotion').agg(\n",
    "        ovr_f1_mean=('ovr_f1', 'mean'),\n",
    "        ovr_f1_var=('ovr_f1', 'var'),\n",
    "        ovr_accuracy_mean=('ovr_accuracy', 'mean'),\n",
    "        ovr_accuracy_var=('ovr_accuracy', 'var'),\n",
    "        rakel_f1_mean=('rakel_f1', 'mean'),\n",
    "        rakel_f1_var=('rakel_f1', 'var'),\n",
    "        rakel_accuracy_mean=('rakel_accuracy', 'mean'),\n",
    "        rakel_accuracy_var=('rakel_accuracy', 'var'),\n",
    "    )\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          ovr_f1_mean  ovr_f1_var  ovr_accuracy_mean  ovr_accuracy_var  \\\n",
       "Emotion                                                                  \n",
       "Anger        0.000000    0.000000           0.000000      0.000000e+00   \n",
       "Fear         0.285714    0.000000           0.166667      0.000000e+00   \n",
       "Interest     0.070936    0.000001           0.036772      2.946814e-07   \n",
       "Joy          0.534615    0.002943           0.366667      2.729045e-03   \n",
       "Love         0.500000    0.000000           0.333333      0.000000e+00   \n",
       "None         0.357143    0.000000           0.217391      0.000000e+00   \n",
       "Sadness      0.000000    0.000000           0.000000      0.000000e+00   \n",
       "Surprise     0.285714    0.000000           0.166667      0.000000e+00   \n",
       "\n",
       "          rakel_f1_mean  rakel_f1_var  rakel_accuracy_mean  rakel_accuracy_var  \n",
       "Emotion                                                                         \n",
       "Anger          0.000000      0.000000             0.000000            0.000000  \n",
       "Fear           0.080769      0.011871             0.045455            0.003915  \n",
       "Interest       0.024103      0.002013             0.012712            0.000567  \n",
       "Joy            0.346107      0.002725             0.210385            0.001391  \n",
       "Love           0.588304      0.000716             0.417214            0.000705  \n",
       "None           0.516430      0.001555             0.348987            0.001236  \n",
       "Sadness        0.000000      0.000000             0.000000            0.000000  \n",
       "Surprise       0.126567      0.008469             0.070109            0.002996  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ovr_f1_mean</th>\n      <th>ovr_f1_var</th>\n      <th>ovr_accuracy_mean</th>\n      <th>ovr_accuracy_var</th>\n      <th>rakel_f1_mean</th>\n      <th>rakel_f1_var</th>\n      <th>rakel_accuracy_mean</th>\n      <th>rakel_accuracy_var</th>\n    </tr>\n    <tr>\n      <th>Emotion</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Anger</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Fear</th>\n      <td>0.285714</td>\n      <td>0.000000</td>\n      <td>0.166667</td>\n      <td>0.000000e+00</td>\n      <td>0.080769</td>\n      <td>0.011871</td>\n      <td>0.045455</td>\n      <td>0.003915</td>\n    </tr>\n    <tr>\n      <th>Interest</th>\n      <td>0.070936</td>\n      <td>0.000001</td>\n      <td>0.036772</td>\n      <td>2.946814e-07</td>\n      <td>0.024103</td>\n      <td>0.002013</td>\n      <td>0.012712</td>\n      <td>0.000567</td>\n    </tr>\n    <tr>\n      <th>Joy</th>\n      <td>0.534615</td>\n      <td>0.002943</td>\n      <td>0.366667</td>\n      <td>2.729045e-03</td>\n      <td>0.346107</td>\n      <td>0.002725</td>\n      <td>0.210385</td>\n      <td>0.001391</td>\n    </tr>\n    <tr>\n      <th>Love</th>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>0.000000e+00</td>\n      <td>0.588304</td>\n      <td>0.000716</td>\n      <td>0.417214</td>\n      <td>0.000705</td>\n    </tr>\n    <tr>\n      <th>None</th>\n      <td>0.357143</td>\n      <td>0.000000</td>\n      <td>0.217391</td>\n      <td>0.000000e+00</td>\n      <td>0.516430</td>\n      <td>0.001555</td>\n      <td>0.348987</td>\n      <td>0.001236</td>\n    </tr>\n    <tr>\n      <th>Sadness</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>Surprise</th>\n      <td>0.285714</td>\n      <td>0.000000</td>\n      <td>0.166667</td>\n      <td>0.000000e+00</td>\n      <td>0.126567</td>\n      <td>0.008469</td>\n      <td>0.070109</td>\n      <td>0.002996</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "calulate_results(results, labels)"
   ]
  },
  {
   "source": [
    "## Test significance between Algorithms\n",
    "\n",
    " use Welch's one-sided t-test\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "\n",
    "use parameter equal_var=False\n",
    "\n",
    "If False, perform Welchâ€™s t-test, which does not assume equal population variance.\n",
    "\n",
    "use parameter alternative='greater' \n",
    "\n",
    "â€˜greaterâ€™: one-sided\n",
    "\n",
    "Todo\n",
    "- compute Welchâ€™s one-sided t-test\n",
    "    - test significance for alpha = (0.05, 0.001)\n",
    "- optional: compute other test statistics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_significance(scores, labels):\n",
    "    results = []\n",
    "    for label in labels:\n",
    "        result = {}\n",
    "        \n",
    "        # calculate p-values for F1\n",
    "        ovr_f1 = scores[scores['Emotion'] == label]['ovr_f1'].values\n",
    "        rakel_f1 = scores[scores['Emotion'] == label]['rakel_f1'].values\n",
    "        welch_f1 = ttest_ind(ovr_f1, rakel_f1, equal_var=False, alternative='greater')\n",
    "        result['f1'] = welch_f1.pvalue\n",
    "\n",
    "        # calculate p-calues for Accuracy\n",
    "        ovr_accuracy = scores[scores['Emotion'] == label]['ovr_accuracy'].values\n",
    "        rakel_accuracy = scores[scores['Emotion'] == label]['rakel_accuracy'].values\n",
    "        welch_accuracy = ttest_ind(ovr_f1, rakel_f1, equal_var=False, alternative='greater')\n",
    "        result['accuracy'] = welch_accuracy.pvalue\n",
    "\n",
    "        results.append(result)\n",
    "    return pd.DataFrame(results, index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    f1      accuracy\n",
       "Anger              NaN           NaN\n",
       "Fear      3.941101e-08  3.941101e-08\n",
       "Interest  8.384537e-05  8.384537e-05\n",
       "Joy       6.852655e-14  6.852655e-14\n",
       "Love      1.000000e+00  1.000000e+00\n",
       "None      1.000000e+00  1.000000e+00\n",
       "Sadness            NaN           NaN\n",
       "Surprise  1.380361e-07  1.380361e-07"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Anger</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Fear</th>\n      <td>3.941101e-08</td>\n      <td>3.941101e-08</td>\n    </tr>\n    <tr>\n      <th>Interest</th>\n      <td>8.384537e-05</td>\n      <td>8.384537e-05</td>\n    </tr>\n    <tr>\n      <th>Joy</th>\n      <td>6.852655e-14</td>\n      <td>6.852655e-14</td>\n    </tr>\n    <tr>\n      <th>Love</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>None</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n    <tr>\n      <th>Sadness</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>Surprise</th>\n      <td>1.380361e-07</td>\n      <td>1.380361e-07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "calculate_significance(results, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDO something runs wrong here the p-values for accuracy and f1 are exactly the same and anger and sadness have NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('reproducibility_multi-emotion_detection': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "046bb29bab8f00f7ae15da26996426ed7578b9a90247bb3024ba28a4fd4b5012"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}